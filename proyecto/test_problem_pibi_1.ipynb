{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "8a2f322e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import os\n",
    "from datetime import datetime\n",
    "from sklearn.datasets import make_spd_matrix\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from scipy.stats import qmc\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "e103405f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def u_analytic(x, y):\n",
    "    return 16*(1 - x) * x * (1 - y) * y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "ab0e1a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def integration_points(n_int):\n",
    "    points = torch.linspace(0, 4, n_int+1)[:-1]\n",
    "    points += torch.rand(points.shape) * (1 / n_int) + np.random.rand() * 0.05 # random shift\n",
    "\n",
    "    # points on square\n",
    "    epsilon = 0.1 # changeable: set the boundary an espilon away from the Omega boundary\n",
    "    side = 2 + 2*epsilon\n",
    "    middle = torch.tensor((0,0)).view(1,2)\n",
    "    points = torch.remainder(points, 4) # transform points to [0,4]\n",
    "    v1 = torch.tensor((0, side))[None,]\n",
    "    v2 = torch.tensor((side, 0))[None,]\n",
    "    v3 = torch.tensor((0, -side))[None,]\n",
    "    v4 = torch.tensor((-side, 0))[None,]\n",
    "    points = points.view(-1,1)\n",
    "    x_int = (middle - 0.5 * (v1 + v2) + torch.clamp(points,0,1) * v1 + torch.clamp(points-1,0,1) * v2 + torch.clamp(points-2,0,1) * v3 + torch.clamp(points-3,0,1) * v4).requires_grad_(True)\n",
    "\n",
    "    return x_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "11aeb79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outer normal directional derivative on boundary of Omega (as a circle)\n",
    "def outer_normal(x):\n",
    "\n",
    "    middle = torch.tensor((0,0)).view(1,2)\n",
    "    max_indices = torch.argmax(torch.abs(x - middle), dim=-1, keepdim=False)\n",
    "    normals = torch.zeros_like(x)\n",
    "    sign = torch.sign(x)\n",
    "    temp_range = torch.arange(x.size(0))\n",
    "    normals[temp_range, max_indices] = sign[temp_range, max_indices]\n",
    "\n",
    "    return normals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "e6eb1db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fundamental solution of Laplace equation in 2D\n",
    "def fundamental_solution(x, y):\n",
    "\n",
    "    distance = torch.norm(x - y, p=2, dim=1).view(-1,1)\n",
    "    Phi_0 = -1/(2*torch.pi) * torch.log(distance)\n",
    "\n",
    "    return Phi_0\n",
    "\n",
    "\n",
    "# gradient of fundamental solution with respect to y\n",
    "# grad Phi_0(x,y) = 1/(2π) * (x - y)/||x - y||²\n",
    "def gradient_fundamental(x, y):\n",
    "\n",
    "    distance = torch.norm(x - y, p=2, dim=1).view(-1,1)\n",
    "    grad_Phi_0 = (1/(2*torch.pi)) * ((x - y) / distance**2)\n",
    "    \n",
    "    return grad_Phi_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345a372b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fully-connected neural network setup with PyTorch\n",
    "class FCNN(nn.Module):\n",
    "    def __init__(self, N_input, N_output, N_hidden, N_layers, n_int):\n",
    "\n",
    "        super().__init__()\n",
    "        activation = nn.Tanh\n",
    "        self.n_int = n_int\n",
    "\n",
    "        # input / start layer\n",
    "        self.fc_start = nn.Sequential(*[\n",
    "                                nn.Linear(N_input, N_hidden),\n",
    "                                activation()\n",
    "                                ])\n",
    "        # hidden layers\n",
    "        self.fc_hidden = nn.Sequential(*[\n",
    "                                nn.Sequential(*[\n",
    "                                    nn.Linear(N_hidden, N_hidden),\n",
    "                                    activation()\n",
    "                                    ])\n",
    "                                for _ in range(N_layers-1) # -1 since first layer already defined before for-loop\n",
    "                                ])\n",
    "        # output / end layer\n",
    "        self.fc_end = nn.Linear(N_hidden, N_output)\n",
    "\n",
    "    #------------------------------\n",
    "    # forward pass through network\n",
    "    def forward(self, x):\n",
    "        # map x to [-1,1]\n",
    "        epsilon = 0.1\n",
    "        x_scaled = 2*(x - torch.tensor([-1-epsilon, -1-epsilon]))/(torch.tensor([1+epsilon, 1+epsilon]) - torch.tensor([-1-epsilon, -1-epsilon])) - 1\n",
    "        #x_scaled = 2*(x - torch.tensor([x_min, y_min]))/(torch.tensor([x_max, y_max]) - torch.tensor([x_min, y_min])) - 1\n",
    "        # forward pass\n",
    "        x_scaled = self.fc_start(x_scaled)  # input layer\n",
    "        x_scaled = self.fc_hidden(x_scaled) # hidden layer(s)\n",
    "        u = self.fc_end(x_scaled)    # output layer\n",
    "        return u\n",
    "\n",
    "    #------------------------------\n",
    "    # calculating the potential integrals\n",
    "    def resample(self):\n",
    "        # sampling new collocation and integration points\n",
    "        self.x_int = integration_points(self.n_int)\n",
    "        # calculating the potential\n",
    "        self.vmapped_potential_inside = torch.vmap(self.calc_potentials_inside, randomness='same')\n",
    "\n",
    "    #------------------------------\n",
    "    # calculating the single and double layer potentials for x being an inside Omega point\n",
    "    def calc_potentials_inside(self, x):\n",
    "\n",
    "        epsilon = 0.1\n",
    "        side = 2 + 2*epsilon\n",
    "\n",
    "        y = self.x_int\n",
    "        normal_y = outer_normal(y)\n",
    "        h_y = self(y) # boundary density, performs forward pass through  neural network with the input y\n",
    "\n",
    "        # single_layer\n",
    "        G = fundamental_solution(x, y)\n",
    "        grad_ones = torch.ones_like(h_y)\n",
    "        dh_dy = torch.autograd.grad(h_y, y, grad_outputs=grad_ones, create_graph=True)[0]\n",
    "        dh_dn = torch.sum(dh_dy * normal_y, dim=1).view(-1, 1)\n",
    "        single_layer = 4*side*torch.mean(G * dh_dn)\n",
    "        ################\n",
    "        # double_layer\n",
    "        dG_dy = gradient_fundamental(x, y)\n",
    "        dG_dn = torch.sum(dG_dy * normal_y, dim=1).view(-1, 1)\n",
    "        double_layer = 4*side*torch.mean(dG_dn * h_y)\n",
    "\n",
    "        #################\n",
    "        # source term\n",
    "        f =  32*((1 - y[:,1])*y[:,1] + (1 - y[:,0])*y[:,0]) \n",
    "        source_term = torch.mean(f)\n",
    "\n",
    "        return single_layer.squeeze(), double_layer.squeeze(), source_term.squeeze()\n",
    "\n",
    "    #------------------------------\n",
    "    def predict_u_inside(self, x):\n",
    "        single_layer, double_layer, source_term = self.vmapped_potential_inside(x)\n",
    "        u_int_data = (single_layer.squeeze() - double_layer.squeeze() + source_term.squeeze()).view(-1, 1)\n",
    "        return u_int_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "e17e147d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialise_pibi(lr, n_int):\n",
    "\n",
    "    # define number of neurons in each layer type\n",
    "    N_input  = 2\n",
    "    N_output = 1\n",
    "    N_hidden = 64 # changeable, use 2**n for efficient memory usage and computation\n",
    "    N_layers = 3 # number of hidden layers\n",
    "\n",
    "    # define a neural network to train\n",
    "    pibi = FCNN(N_input, N_output, N_hidden, N_layers, n_int)\n",
    "    \n",
    "    # optimizer\n",
    "    optimiser = torch.optim.Adam(pibi.parameters(), lr=lr)\n",
    "\n",
    "    # loss function\n",
    "    mse_loss = torch.nn.MSELoss() # Mean squared error\n",
    "    \n",
    "    return pibi, optimiser, mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "876d71f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número de muestras a generar (para malla regular y para LHS)\n",
    "n_samples = 30 # number of samples\n",
    "n_int = 400 # number of integration points\n",
    "\n",
    "# Crear malla regular en el dominio [0,1]x[0,1]\n",
    "x = np.linspace(-1, 1, n_samples)\n",
    "y = np.linspace(-1, 1, n_samples)\n",
    "X_grid, Y_grid = np.meshgrid(x, y)\n",
    "\n",
    "# Evaluar solución analítica sobre la malla regular\n",
    "U_grid = u_analytic(X_grid, Y_grid)\n",
    "\n",
    "# Aplanar y combinar en una matriz (x, y, u) para la malla regular\n",
    "num_points = n_samples ** 2\n",
    "XU_grid = np.column_stack((\n",
    "    X_grid.reshape(num_points),\n",
    "    Y_grid.reshape(num_points),\n",
    "    U_grid.reshape(num_points)\n",
    "))\n",
    "\n",
    "# Generar muestras usando Latin Hypercube Sampling (LHS)\n",
    "lhs_sampler = qmc.LatinHypercube(d=2)\n",
    "lhs_samples = lhs_sampler.random(n=n_samples)\n",
    "\n",
    "# Escalar las muestras al dominio [0,1]x[0,1]\n",
    "domain_bounds_lower = [0, 0]\n",
    "domain_bounds_upper = [1, 1]\n",
    "lhs_scaled = qmc.scale(lhs_samples, domain_bounds_lower, domain_bounds_upper)\n",
    "\n",
    "# Evaluar solución analítica en las muestras LHS\n",
    "X_lhs, Y_lhs = lhs_scaled[:, 0], lhs_scaled[:, 1]\n",
    "U_lhs = u_analytic(X_lhs, Y_lhs)\n",
    "\n",
    "# Combinar en una matriz (x, y, u) para las muestras LHS\n",
    "XU_lhs = np.column_stack((X_lhs, Y_lhs, U_lhs))\n",
    "\n",
    "# generar puntos de integración\n",
    "x_int = integration_points(n_int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "76d359a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(U_grid)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "7a219e25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot outer normal and x_int\n",
    "figure, ax = plt.subplots(figsize=(4, 4))\n",
    "plt.scatter(x_int[:, 0].detach().numpy(), x_int[:, 1].detach().numpy())\n",
    "plt.scatter(x_int[5, 0].detach().numpy(), x_int[5, 1].detach().numpy())\n",
    "plt.show()\n",
    "#plt.quiver(x_int[:, 0].detach().numpy(), x_int[:, 1].detach().numpy(), outer_normal(x_int)[:, 0].detach().numpy(), outer_normal(x_int)[:, 1].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "70fa1097",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pibi(iterations, pibi, optimiser, mse_loss, data, data_n, n_samples, n_int, time_now, show_plots):\n",
    "\n",
    "    # store loss values\n",
    "    loss_values = []\n",
    " \n",
    "    for epoch in range(iterations):\n",
    "\n",
    "        # Clear gradients before forward and backward pass for each batch to avoid accumulation of gradients\n",
    "        optimiser.zero_grad()\n",
    "\n",
    "        # compute data loss\n",
    "        pibi.resample()\n",
    "        u_int_data = pibi.predict_u_inside(data[:,0:2])\n",
    "        loss = mse_loss(u_int_data, data[:,-1].view(-1,1))\n",
    "        loss_values.append(loss.item())\n",
    "\n",
    "        # backpropagate loss, take optimiser step\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        print('Epoch:', epoch, 'Loss:', loss.item())\n",
    "\n",
    "    return pibi, loss_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "312c03af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss: 92034444324.69937\n",
      "Epoch: 1 Loss: 92050599286.88911\n",
      "Epoch: 2 Loss: 92038761003.72147\n",
      "Epoch: 3 Loss: 91995489731.53201\n",
      "Epoch: 4 Loss: 92047918926.91904\n",
      "Epoch: 5 Loss: 92044956186.25185\n",
      "Epoch: 6 Loss: 92004694820.30927\n",
      "Epoch: 7 Loss: 92028433353.7456\n",
      "Epoch: 8 Loss: 91977867513.26793\n",
      "Epoch: 9 Loss: 92057383994.31561\n",
      "Epoch: 10 Loss: 92001958388.11426\n",
      "Epoch: 11 Loss: 92031771963.46214\n",
      "Epoch: 12 Loss: 91997475768.31195\n",
      "Epoch: 13 Loss: 92044955665.31453\n",
      "Epoch: 14 Loss: 92099940231.82094\n",
      "Epoch: 15 Loss: 91996877175.25621\n",
      "Epoch: 16 Loss: 91971975471.79646\n",
      "Epoch: 17 Loss: 92037753635.6665\n",
      "Epoch: 18 Loss: 92098650176.56136\n",
      "Epoch: 19 Loss: 92025164700.70921\n",
      "Epoch: 20 Loss: 92028539896.11484\n",
      "Epoch: 21 Loss: 91944940853.09766\n",
      "Epoch: 22 Loss: 91962892307.7892\n",
      "Epoch: 23 Loss: 92079082837.67813\n",
      "Epoch: 24 Loss: 91987956841.40163\n",
      "Epoch: 25 Loss: 92112569550.94955\n",
      "Epoch: 26 Loss: 92085120102.3763\n",
      "Epoch: 27 Loss: 92015170318.81465\n",
      "Epoch: 28 Loss: 91921127333.1026\n",
      "Epoch: 29 Loss: 92084114054.56813\n",
      "Epoch: 30 Loss: 92041003119.28795\n",
      "Epoch: 31 Loss: 92063340869.404\n",
      "Epoch: 32 Loss: 92052374433.5943\n",
      "Epoch: 33 Loss: 92035920790.03568\n",
      "Epoch: 34 Loss: 92039211515.46428\n",
      "Epoch: 35 Loss: 92005414487.20058\n",
      "Epoch: 36 Loss: 92075864901.57516\n",
      "Epoch: 37 Loss: 92032548355.18869\n",
      "Epoch: 38 Loss: 91986487283.21678\n",
      "Epoch: 39 Loss: 91994575505.63443\n",
      "Epoch: 40 Loss: 92068685102.59653\n",
      "Epoch: 41 Loss: 92059766007.4213\n",
      "Epoch: 42 Loss: 91996963457.9116\n",
      "Epoch: 43 Loss: 92029896235.50333\n",
      "Epoch: 44 Loss: 91962117720.99434\n",
      "Epoch: 45 Loss: 92052626690.86543\n",
      "Epoch: 46 Loss: 92047180876.51308\n",
      "Epoch: 47 Loss: 91995281339.0818\n",
      "Epoch: 48 Loss: 92013793776.03435\n",
      "Epoch: 49 Loss: 91996787389.14952\n",
      "Epoch: 50 Loss: 91962323732.1024\n",
      "Epoch: 51 Loss: 92000089469.73723\n",
      "Epoch: 52 Loss: 92013245537.55582\n",
      "Epoch: 53 Loss: 92020363767.1704\n",
      "Epoch: 54 Loss: 91950076353.27661\n",
      "Epoch: 55 Loss: 91973227449.3837\n",
      "Epoch: 56 Loss: 92072047988.26762\n",
      "Epoch: 57 Loss: 91934622293.53412\n",
      "Epoch: 58 Loss: 92014403016.70416\n",
      "Epoch: 59 Loss: 91972781483.95537\n",
      "Epoch: 60 Loss: 92002546591.90425\n",
      "Epoch: 61 Loss: 91970017156.0305\n",
      "Epoch: 62 Loss: 91976523889.19037\n",
      "Epoch: 63 Loss: 91964373080.55952\n",
      "Epoch: 64 Loss: 92007277735.57802\n",
      "Epoch: 65 Loss: 91962076022.32236\n",
      "Epoch: 66 Loss: 91993013101.42079\n",
      "Epoch: 67 Loss: 91949423655.53448\n",
      "Epoch: 68 Loss: 92170591607.15457\n",
      "Epoch: 69 Loss: 92057930407.22\n",
      "Epoch: 70 Loss: 92045744905.5934\n",
      "Epoch: 71 Loss: 92005539368.83406\n",
      "Epoch: 72 Loss: 91986967542.39735\n",
      "Epoch: 73 Loss: 92053865215.64792\n",
      "Epoch: 74 Loss: 91991528733.32251\n",
      "Epoch: 75 Loss: 92008150319.97617\n",
      "Epoch: 76 Loss: 92074228527.97314\n",
      "Epoch: 77 Loss: 92033999859.439\n",
      "Epoch: 78 Loss: 92119055049.92773\n",
      "Epoch: 79 Loss: 91991516633.84102\n",
      "Epoch: 80 Loss: 91983474799.95102\n",
      "Epoch: 81 Loss: 91963813307.37408\n",
      "Epoch: 82 Loss: 92013745696.13661\n",
      "Epoch: 83 Loss: 92004644434.25029\n",
      "Epoch: 84 Loss: 92020008192.42088\n",
      "Epoch: 85 Loss: 91995896620.01772\n",
      "Epoch: 86 Loss: 92041685662.13576\n",
      "Epoch: 87 Loss: 91967860610.68573\n",
      "Epoch: 88 Loss: 92013577217.75806\n",
      "Epoch: 89 Loss: 91903226079.28223\n",
      "Epoch: 90 Loss: 91946355169.64473\n",
      "Epoch: 91 Loss: 91989246971.52695\n",
      "Epoch: 92 Loss: 92032170770.53812\n",
      "Epoch: 93 Loss: 92023812507.20537\n",
      "Epoch: 94 Loss: 92004946807.01399\n",
      "Epoch: 95 Loss: 92084470905.29857\n",
      "Epoch: 96 Loss: 91955631959.67207\n",
      "Epoch: 97 Loss: 92031834900.56161\n",
      "Epoch: 98 Loss: 92053259062.43245\n",
      "Epoch: 99 Loss: 91953961702.12175\n",
      "Epoch: 100 Loss: 92024489393.58595\n",
      "Epoch: 101 Loss: 92024096436.12288\n",
      "Epoch: 102 Loss: 92053403942.28198\n",
      "Epoch: 103 Loss: 91991770222.66087\n",
      "Epoch: 104 Loss: 92006373867.84914\n",
      "Epoch: 105 Loss: 91979344942.80045\n",
      "Epoch: 106 Loss: 92043928274.36119\n",
      "Epoch: 107 Loss: 92043453198.83261\n",
      "Epoch: 108 Loss: 92051192726.88405\n",
      "Epoch: 109 Loss: 92038417121.16202\n",
      "Epoch: 110 Loss: 92091656755.95612\n",
      "Epoch: 111 Loss: 92029207747.81447\n",
      "Epoch: 112 Loss: 91957352121.2103\n",
      "Epoch: 113 Loss: 91901603489.74745\n",
      "Epoch: 114 Loss: 92029309291.97572\n",
      "Epoch: 115 Loss: 92024733777.07468\n",
      "Epoch: 116 Loss: 92031204238.0891\n",
      "Epoch: 117 Loss: 92003329991.15874\n",
      "Epoch: 118 Loss: 91965825851.05101\n",
      "Epoch: 119 Loss: 91990747332.614\n",
      "Epoch: 120 Loss: 91988474533.36044\n",
      "Epoch: 121 Loss: 92033450673.88686\n",
      "Epoch: 122 Loss: 92062248547.77003\n",
      "Epoch: 123 Loss: 92089464217.76566\n",
      "Epoch: 124 Loss: 91928486205.94685\n",
      "Epoch: 125 Loss: 91964705748.46902\n",
      "Epoch: 126 Loss: 91924369757.8629\n",
      "Epoch: 127 Loss: 92074326782.74307\n",
      "Epoch: 128 Loss: 91957585823.63197\n",
      "Epoch: 129 Loss: 91986081062.5625\n",
      "Epoch: 130 Loss: 91978801031.34535\n",
      "Epoch: 131 Loss: 91939483579.98518\n",
      "Epoch: 132 Loss: 91909846098.75215\n",
      "Epoch: 133 Loss: 91887755409.37076\n",
      "Epoch: 134 Loss: 92005428903.43613\n",
      "Epoch: 135 Loss: 91975037342.96286\n",
      "Epoch: 136 Loss: 91891981652.39763\n",
      "Epoch: 137 Loss: 91960155519.94904\n",
      "Epoch: 138 Loss: 92026278498.66875\n",
      "Epoch: 139 Loss: 91952270882.15608\n",
      "Epoch: 140 Loss: 92027262245.49623\n",
      "Epoch: 141 Loss: 91905023343.11555\n",
      "Epoch: 142 Loss: 92042710316.32509\n",
      "Epoch: 143 Loss: 91968369907.34074\n",
      "Epoch: 144 Loss: 91963408540.48325\n",
      "Epoch: 145 Loss: 91951709714.8597\n",
      "Epoch: 146 Loss: 91896261520.02577\n",
      "Epoch: 147 Loss: 91933327830.09286\n",
      "Epoch: 148 Loss: 92047489925.40817\n",
      "Epoch: 149 Loss: 91966952806.2043\n",
      "Epoch: 150 Loss: 91997933016.51384\n",
      "Epoch: 151 Loss: 92020066211.64977\n",
      "Epoch: 152 Loss: 91987175478.34286\n",
      "Epoch: 153 Loss: 91978040938.33739\n",
      "Epoch: 154 Loss: 91963968977.38072\n",
      "Epoch: 155 Loss: 91932385129.99113\n",
      "Epoch: 156 Loss: 91960018889.19792\n",
      "Epoch: 157 Loss: 91939319339.42038\n",
      "Epoch: 158 Loss: 91968023980.88222\n",
      "Epoch: 159 Loss: 91911101188.18513\n",
      "Epoch: 160 Loss: 91958586208.91566\n",
      "Epoch: 161 Loss: 91944814511.45413\n",
      "Epoch: 162 Loss: 91893967157.10278\n",
      "Epoch: 163 Loss: 91882477886.15996\n",
      "Epoch: 164 Loss: 91971409029.59975\n",
      "Epoch: 165 Loss: 91930367781.61162\n",
      "Epoch: 166 Loss: 91961198518.64809\n",
      "Epoch: 167 Loss: 91933722161.68478\n",
      "Epoch: 168 Loss: 91945665788.42336\n",
      "Epoch: 169 Loss: 91921564527.29837\n",
      "Epoch: 170 Loss: 91850029818.03448\n",
      "Epoch: 171 Loss: 91803386429.21742\n",
      "Epoch: 172 Loss: 91950758898.91068\n",
      "Epoch: 173 Loss: 91879318737.1402\n",
      "Epoch: 174 Loss: 91836205619.26877\n",
      "Epoch: 175 Loss: 91881849948.02618\n",
      "Epoch: 176 Loss: 91956882601.99889\n",
      "Epoch: 177 Loss: 91798691168.40413\n",
      "Epoch: 178 Loss: 91959906427.5413\n",
      "Epoch: 179 Loss: 91873005348.5035\n",
      "Epoch: 180 Loss: 91890791138.74805\n",
      "Epoch: 181 Loss: 91954277415.51556\n",
      "Epoch: 182 Loss: 91921294050.46909\n",
      "Epoch: 183 Loss: 91873950856.44054\n",
      "Epoch: 184 Loss: 91859937125.81712\n",
      "Epoch: 185 Loss: 91917079531.77135\n",
      "Epoch: 186 Loss: 91850166224.24428\n",
      "Epoch: 187 Loss: 91839660020.3397\n",
      "Epoch: 188 Loss: 91910084557.87093\n",
      "Epoch: 189 Loss: 91945724536.73975\n",
      "Epoch: 190 Loss: 91866635711.13625\n",
      "Epoch: 191 Loss: 91933670794.61412\n",
      "Epoch: 192 Loss: 91906501150.54274\n",
      "Epoch: 193 Loss: 91926040651.68213\n",
      "Epoch: 194 Loss: 91764063258.0627\n",
      "Epoch: 195 Loss: 91888172576.951\n",
      "Epoch: 196 Loss: 91849879365.92978\n",
      "Epoch: 197 Loss: 91893172990.75792\n",
      "Epoch: 198 Loss: 91851329407.74811\n",
      "Epoch: 199 Loss: 91824504270.07771\n",
      "Epoch: 200 Loss: 91835914865.598\n",
      "Epoch: 201 Loss: 91753520563.33984\n",
      "Epoch: 202 Loss: 91883098603.30424\n",
      "Epoch: 203 Loss: 91779600986.17575\n",
      "Epoch: 204 Loss: 91820581987.54776\n",
      "Epoch: 205 Loss: 91868583447.95853\n",
      "Epoch: 206 Loss: 91793339828.81253\n",
      "Epoch: 207 Loss: 91836559316.65999\n",
      "Epoch: 208 Loss: 91819933523.9733\n",
      "Epoch: 209 Loss: 91813525985.11922\n",
      "Epoch: 210 Loss: 91704666277.59512\n",
      "Epoch: 211 Loss: 91807783403.30574\n",
      "Epoch: 212 Loss: 91807611951.14362\n",
      "Epoch: 213 Loss: 91784937453.31152\n",
      "Epoch: 214 Loss: 91821783679.54596\n",
      "Epoch: 215 Loss: 91794129860.06377\n",
      "Epoch: 216 Loss: 91739741572.11075\n",
      "Epoch: 217 Loss: 91707637510.37764\n",
      "Epoch: 218 Loss: 91791714190.54948\n",
      "Epoch: 219 Loss: 91825500067.89821\n",
      "Epoch: 220 Loss: 91805164725.23201\n",
      "Epoch: 221 Loss: 91726123201.69434\n",
      "Epoch: 222 Loss: 91808427141.3376\n",
      "Epoch: 223 Loss: 91733170394.653\n",
      "Epoch: 224 Loss: 91777084614.3216\n",
      "Epoch: 225 Loss: 91732917134.9527\n",
      "Epoch: 226 Loss: 91731841224.58629\n",
      "Epoch: 227 Loss: 91737891183.81982\n",
      "Epoch: 228 Loss: 91680038030.08379\n",
      "Epoch: 229 Loss: 91710761771.21475\n",
      "Epoch: 230 Loss: 91744597849.42024\n",
      "Epoch: 231 Loss: 91682729647.41971\n",
      "Epoch: 232 Loss: 91673060043.00412\n",
      "Epoch: 233 Loss: 91782868999.9022\n",
      "Epoch: 234 Loss: 91669829666.32164\n",
      "Epoch: 235 Loss: 91635214767.89444\n",
      "Epoch: 236 Loss: 91691746422.22444\n",
      "Epoch: 237 Loss: 91677688448.96577\n",
      "Epoch: 238 Loss: 91604031032.43117\n",
      "Epoch: 239 Loss: 91656416552.73642\n",
      "Epoch: 240 Loss: 91689429597.26846\n",
      "Epoch: 241 Loss: 91722490543.19304\n",
      "Epoch: 242 Loss: 91619927282.11923\n",
      "Epoch: 243 Loss: 91672031582.73857\n",
      "Epoch: 244 Loss: 91645639445.25366\n",
      "Epoch: 245 Loss: 91667863026.70602\n",
      "Epoch: 246 Loss: 91644855510.59508\n",
      "Epoch: 247 Loss: 91669213552.61598\n",
      "Epoch: 248 Loss: 91639596187.697\n",
      "Epoch: 249 Loss: 91612649588.5944\n",
      "Epoch: 250 Loss: 91735222124.40521\n",
      "Epoch: 251 Loss: 91614763797.2414\n",
      "Epoch: 252 Loss: 91607170026.07178\n",
      "Epoch: 253 Loss: 91738365243.9751\n",
      "Epoch: 254 Loss: 91620236766.54291\n",
      "Epoch: 255 Loss: 91672159439.16289\n",
      "Epoch: 256 Loss: 91616558639.8999\n",
      "Epoch: 257 Loss: 91629276379.82549\n",
      "Epoch: 258 Loss: 91607355904.40816\n",
      "Epoch: 259 Loss: 91616374115.98447\n",
      "Epoch: 260 Loss: 91680796671.16771\n",
      "Epoch: 261 Loss: 91596153197.39804\n",
      "Epoch: 262 Loss: 91641773526.00732\n",
      "Epoch: 263 Loss: 91581500907.39288\n",
      "Epoch: 264 Loss: 91515120018.90974\n",
      "Epoch: 265 Loss: 91635296434.60948\n",
      "Epoch: 266 Loss: 91568352623.75652\n",
      "Epoch: 267 Loss: 91550671320.24664\n",
      "Epoch: 268 Loss: 91578778841.72133\n",
      "Epoch: 269 Loss: 91483903996.65283\n",
      "Epoch: 270 Loss: 91551565154.21901\n",
      "Epoch: 271 Loss: 91646985525.31676\n",
      "Epoch: 272 Loss: 91456598568.2267\n",
      "Epoch: 273 Loss: 91555696501.22295\n",
      "Epoch: 274 Loss: 91576204013.96107\n",
      "Epoch: 275 Loss: 91494715643.03363\n",
      "Epoch: 276 Loss: 91514675318.42902\n",
      "Epoch: 277 Loss: 91418782838.02623\n",
      "Epoch: 278 Loss: 91547423146.31812\n",
      "Epoch: 279 Loss: 91441174726.30249\n",
      "Epoch: 280 Loss: 91463844520.92966\n",
      "Epoch: 281 Loss: 91433730374.2488\n",
      "Epoch: 282 Loss: 91422889256.94832\n",
      "Epoch: 283 Loss: 91485637594.73346\n",
      "Epoch: 284 Loss: 91478933522.41241\n",
      "Epoch: 285 Loss: 91412821854.00468\n",
      "Epoch: 286 Loss: 91405219549.70331\n",
      "Epoch: 287 Loss: 91432563132.07161\n",
      "Epoch: 288 Loss: 91501774173.222\n",
      "Epoch: 289 Loss: 91469694907.53102\n",
      "Epoch: 290 Loss: 91384503560.9606\n",
      "Epoch: 291 Loss: 91399509898.7242\n",
      "Epoch: 292 Loss: 91414165042.05687\n",
      "Epoch: 293 Loss: 91477462434.51035\n",
      "Epoch: 294 Loss: 91459823010.4177\n",
      "Epoch: 295 Loss: 91359931918.39037\n",
      "Epoch: 296 Loss: 91399637058.32362\n",
      "Epoch: 297 Loss: 91357795360.65999\n",
      "Epoch: 298 Loss: 91384020362.62346\n",
      "Epoch: 299 Loss: 91346691050.94269\n",
      "Epoch: 300 Loss: 91424191926.21005\n",
      "Epoch: 301 Loss: 91415812530.22845\n",
      "Epoch: 302 Loss: 91385767506.85777\n",
      "Epoch: 303 Loss: 91349402922.25763\n",
      "Epoch: 304 Loss: 91387191759.78117\n",
      "Epoch: 305 Loss: 91442697576.81953\n",
      "Epoch: 306 Loss: 91373570222.40817\n",
      "Epoch: 307 Loss: 91285475862.9385\n",
      "Epoch: 308 Loss: 91290389993.84224\n",
      "Epoch: 309 Loss: 91343238445.85176\n",
      "Epoch: 310 Loss: 91352006285.33842\n",
      "Epoch: 311 Loss: 91299500033.89748\n",
      "Epoch: 312 Loss: 91293455734.32352\n",
      "Epoch: 313 Loss: 91359580626.5662\n",
      "Epoch: 314 Loss: 91288306166.72461\n",
      "Epoch: 315 Loss: 91284529549.17975\n",
      "Epoch: 316 Loss: 91302558498.51994\n",
      "Epoch: 317 Loss: 91286840758.57701\n",
      "Epoch: 318 Loss: 91241993643.5849\n",
      "Epoch: 319 Loss: 91277386174.64655\n",
      "Epoch: 320 Loss: 91239778628.47177\n",
      "Epoch: 321 Loss: 91264158052.688\n",
      "Epoch: 322 Loss: 91217226634.6254\n",
      "Epoch: 323 Loss: 91242767962.63431\n",
      "Epoch: 324 Loss: 91251105670.61101\n",
      "Epoch: 325 Loss: 91229574374.0074\n",
      "Epoch: 326 Loss: 91223912609.03223\n",
      "Epoch: 327 Loss: 91197152728.1547\n",
      "Epoch: 328 Loss: 91158948170.23465\n",
      "Epoch: 329 Loss: 91184343132.93187\n",
      "Epoch: 330 Loss: 91271308273.97856\n",
      "Epoch: 331 Loss: 91152487616.31161\n",
      "Epoch: 332 Loss: 91200767003.28502\n",
      "Epoch: 333 Loss: 91184607751.46622\n",
      "Epoch: 334 Loss: 91193335910.69699\n",
      "Epoch: 335 Loss: 91206323252.03249\n",
      "Epoch: 336 Loss: 91161613903.86641\n",
      "Epoch: 337 Loss: 91109899917.49658\n",
      "Epoch: 338 Loss: 91199635614.46701\n",
      "Epoch: 339 Loss: 91073872549.73776\n",
      "Epoch: 340 Loss: 91169152474.05789\n",
      "Epoch: 341 Loss: 91144068943.99367\n",
      "Epoch: 342 Loss: 91100784573.33958\n",
      "Epoch: 343 Loss: 91047219358.06909\n",
      "Epoch: 344 Loss: 91001944962.79945\n",
      "Epoch: 345 Loss: 91078430827.49477\n",
      "Epoch: 346 Loss: 91152746204.75218\n",
      "Epoch: 347 Loss: 91042004034.08304\n",
      "Epoch: 348 Loss: 91148400035.6679\n",
      "Epoch: 349 Loss: 91134265966.27768\n",
      "Epoch: 350 Loss: 91020791173.1594\n",
      "Epoch: 351 Loss: 91012771994.24286\n",
      "Epoch: 352 Loss: 91090932181.28972\n",
      "Epoch: 353 Loss: 91137090312.50479\n",
      "Epoch: 354 Loss: 91063596752.57625\n",
      "Epoch: 355 Loss: 91076858039.99948\n",
      "Epoch: 356 Loss: 91055520887.03468\n",
      "Epoch: 357 Loss: 91066737617.32454\n",
      "Epoch: 358 Loss: 91036634575.72296\n",
      "Epoch: 359 Loss: 91026492028.92589\n",
      "Epoch: 360 Loss: 90934449896.49458\n",
      "Epoch: 361 Loss: 90978390831.2579\n",
      "Epoch: 362 Loss: 91008762499.92351\n",
      "Epoch: 363 Loss: 90994835545.6503\n",
      "Epoch: 364 Loss: 90988187519.76927\n",
      "Epoch: 365 Loss: 90954475845.7337\n",
      "Epoch: 366 Loss: 91036779735.49863\n",
      "Epoch: 367 Loss: 90929576295.44504\n",
      "Epoch: 368 Loss: 90964182571.71259\n",
      "Epoch: 369 Loss: 90964807675.96817\n",
      "Epoch: 370 Loss: 90816640269.91112\n",
      "Epoch: 371 Loss: 90925159338.55537\n",
      "Epoch: 372 Loss: 90926567412.00687\n",
      "Epoch: 373 Loss: 90920861465.44691\n",
      "Epoch: 374 Loss: 90913823278.36359\n",
      "Epoch: 375 Loss: 90971493390.37784\n",
      "Epoch: 376 Loss: 90888353486.17241\n",
      "Epoch: 377 Loss: 90923566440.5016\n",
      "Epoch: 378 Loss: 90845161841.51674\n",
      "Epoch: 379 Loss: 90791307896.27634\n",
      "Epoch: 380 Loss: 90930328374.72812\n",
      "Epoch: 381 Loss: 90871802415.81947\n",
      "Epoch: 382 Loss: 90869917341.8355\n",
      "Epoch: 383 Loss: 90843593504.72833\n",
      "Epoch: 384 Loss: 90902341817.10078\n",
      "Epoch: 385 Loss: 90788948493.21414\n",
      "Epoch: 386 Loss: 90872465833.41122\n",
      "Epoch: 387 Loss: 90755589201.50104\n",
      "Epoch: 388 Loss: 90806360454.90837\n",
      "Epoch: 389 Loss: 90834118945.64378\n",
      "Epoch: 390 Loss: 90890453489.78592\n",
      "Epoch: 391 Loss: 90804132348.93245\n",
      "Epoch: 392 Loss: 90779011952.24251\n",
      "Epoch: 393 Loss: 90791995547.01076\n",
      "Epoch: 394 Loss: 90750872591.44583\n",
      "Epoch: 395 Loss: 90681349374.91568\n",
      "Epoch: 396 Loss: 90843021371.68439\n",
      "Epoch: 397 Loss: 90784340945.8026\n",
      "Epoch: 398 Loss: 90789589346.03467\n",
      "Epoch: 399 Loss: 90806127095.45694\n",
      "Epoch: 400 Loss: 90731276552.70392\n",
      "Epoch: 401 Loss: 90600905730.69194\n",
      "Epoch: 402 Loss: 90716075302.98346\n",
      "Epoch: 403 Loss: 90717227536.5292\n",
      "Epoch: 404 Loss: 90702107942.86646\n",
      "Epoch: 405 Loss: 90639560958.25877\n",
      "Epoch: 406 Loss: 90780636536.93845\n",
      "Epoch: 407 Loss: 90777703676.77997\n",
      "Epoch: 408 Loss: 90704887312.33064\n",
      "Epoch: 409 Loss: 90620229470.52994\n",
      "Epoch: 410 Loss: 90588898433.5732\n",
      "Epoch: 411 Loss: 90601798465.22755\n",
      "Epoch: 412 Loss: 90661583552.57115\n",
      "Epoch: 413 Loss: 90574840955.45378\n",
      "Epoch: 414 Loss: 90655202941.22346\n",
      "Epoch: 415 Loss: 90678218809.60693\n",
      "Epoch: 416 Loss: 90702537114.99829\n",
      "Epoch: 417 Loss: 90661212019.4811\n",
      "Epoch: 418 Loss: 90609567837.24417\n",
      "Epoch: 419 Loss: 90574257833.28397\n",
      "Epoch: 420 Loss: 90631550949.23314\n",
      "Epoch: 421 Loss: 90565687384.30411\n",
      "Epoch: 422 Loss: 90549278360.7038\n",
      "Epoch: 423 Loss: 90549434947.09232\n",
      "Epoch: 424 Loss: 90640487246.17168\n",
      "Epoch: 425 Loss: 90568775862.37885\n",
      "Epoch: 426 Loss: 90578235428.81015\n",
      "Epoch: 427 Loss: 90557303501.10175\n",
      "Epoch: 428 Loss: 90499015249.2569\n",
      "Epoch: 429 Loss: 90553843271.96852\n",
      "Epoch: 430 Loss: 90510955171.55424\n",
      "Epoch: 431 Loss: 90544297784.35841\n",
      "Epoch: 432 Loss: 90535564215.42767\n",
      "Epoch: 433 Loss: 90559314015.9625\n",
      "Epoch: 434 Loss: 90584192757.13239\n",
      "Epoch: 435 Loss: 90506721313.16255\n",
      "Epoch: 436 Loss: 90449219856.33223\n",
      "Epoch: 437 Loss: 90422308519.02222\n",
      "Epoch: 438 Loss: 90422862563.20963\n",
      "Epoch: 439 Loss: 90341999763.72119\n",
      "Epoch: 440 Loss: 90423992979.99507\n",
      "Epoch: 441 Loss: 90368270716.36417\n",
      "Epoch: 442 Loss: 90413241891.81624\n",
      "Epoch: 443 Loss: 90387844764.72447\n",
      "Epoch: 444 Loss: 90424777681.3244\n",
      "Epoch: 445 Loss: 90506590150.55513\n",
      "Epoch: 446 Loss: 90334493134.20563\n",
      "Epoch: 447 Loss: 90307698203.26076\n",
      "Epoch: 448 Loss: 90347967657.09248\n",
      "Epoch: 449 Loss: 90289128366.70306\n",
      "Epoch: 450 Loss: 90300251207.26855\n",
      "Epoch: 451 Loss: 90332842137.60596\n",
      "Epoch: 452 Loss: 90384443900.441\n",
      "Epoch: 453 Loss: 90374964312.80777\n",
      "Epoch: 454 Loss: 90348968334.72908\n",
      "Epoch: 455 Loss: 90306472894.18027\n",
      "Epoch: 456 Loss: 90264318116.50194\n",
      "Epoch: 457 Loss: 90224383254.04288\n",
      "Epoch: 458 Loss: 90252377606.29977\n",
      "Epoch: 459 Loss: 90267323902.2188\n",
      "Epoch: 460 Loss: 90282094881.29672\n",
      "Epoch: 461 Loss: 90367140820.59976\n",
      "Epoch: 462 Loss: 90372996429.67392\n",
      "Epoch: 463 Loss: 90243398067.7933\n",
      "Epoch: 464 Loss: 90266373193.2611\n",
      "Epoch: 465 Loss: 90147072729.2596\n",
      "Epoch: 466 Loss: 90198662797.24074\n",
      "Epoch: 467 Loss: 90115900131.48709\n",
      "Epoch: 468 Loss: 90222563314.90552\n",
      "Epoch: 469 Loss: 90193322666.78105\n",
      "Epoch: 470 Loss: 90261056754.2109\n",
      "Epoch: 471 Loss: 90225685206.38408\n",
      "Epoch: 472 Loss: 90126691216.1205\n",
      "Epoch: 473 Loss: 90162832320.64911\n",
      "Epoch: 474 Loss: 90087635590.73492\n",
      "Epoch: 475 Loss: 90147942260.89983\n",
      "Epoch: 476 Loss: 90137901162.01675\n",
      "Epoch: 477 Loss: 90109933486.75816\n",
      "Epoch: 478 Loss: 90158395627.63118\n",
      "Epoch: 479 Loss: 90142369827.27702\n",
      "Epoch: 480 Loss: 90219170852.05498\n",
      "Epoch: 481 Loss: 90218486487.1251\n",
      "Epoch: 482 Loss: 90098451946.85135\n",
      "Epoch: 483 Loss: 90059154184.30295\n",
      "Epoch: 484 Loss: 90009666946.9332\n",
      "Epoch: 485 Loss: 89876790429.61035\n",
      "Epoch: 486 Loss: 90104776282.05928\n",
      "Epoch: 487 Loss: 90096890183.77676\n",
      "Epoch: 488 Loss: 90150949011.01724\n",
      "Epoch: 489 Loss: 90121180513.91579\n",
      "Epoch: 490 Loss: 90050937860.64076\n",
      "Epoch: 491 Loss: 90017214735.17772\n",
      "Epoch: 492 Loss: 89957545409.27373\n",
      "Epoch: 493 Loss: 89873303978.64409\n",
      "Epoch: 494 Loss: 89941680954.56363\n",
      "Epoch: 495 Loss: 89987947466.17844\n",
      "Epoch: 496 Loss: 90034980566.2731\n",
      "Epoch: 497 Loss: 90045343942.97481\n",
      "Epoch: 498 Loss: 89996979365.88956\n",
      "Epoch: 499 Loss: 89847991850.38518\n",
      "Epoch: 500 Loss: 89929258163.68967\n",
      "Epoch: 501 Loss: 89920720709.74477\n",
      "Epoch: 502 Loss: 89753164137.56035\n",
      "Epoch: 503 Loss: 89854354063.03622\n",
      "Epoch: 504 Loss: 89873146970.43375\n",
      "Epoch: 505 Loss: 89810880327.78401\n",
      "Epoch: 506 Loss: 89851681626.45566\n",
      "Epoch: 507 Loss: 89905704060.73672\n",
      "Epoch: 508 Loss: 89942921172.70065\n",
      "Epoch: 509 Loss: 89847339443.87802\n",
      "Epoch: 510 Loss: 89813809753.31789\n",
      "Epoch: 511 Loss: 89812313437.59644\n",
      "Epoch: 512 Loss: 89740271198.75702\n",
      "Epoch: 513 Loss: 89842937917.5266\n",
      "Epoch: 514 Loss: 89824924900.26358\n",
      "Epoch: 515 Loss: 89854509888.00264\n",
      "Epoch: 516 Loss: 89895335655.63242\n",
      "Epoch: 517 Loss: 89855167896.99236\n",
      "Epoch: 518 Loss: 89864100169.40706\n",
      "Epoch: 519 Loss: 89670032271.37923\n",
      "Epoch: 520 Loss: 89650920853.09676\n",
      "Epoch: 521 Loss: 89633535864.20055\n",
      "Epoch: 522 Loss: 89673309916.92415\n",
      "Epoch: 523 Loss: 89646154244.79662\n",
      "Epoch: 524 Loss: 89643056685.26556\n",
      "Epoch: 525 Loss: 89745829060.05418\n",
      "Epoch: 526 Loss: 89854973614.0602\n",
      "Epoch: 527 Loss: 89775325243.83469\n",
      "Epoch: 528 Loss: 89781861125.92374\n",
      "Epoch: 529 Loss: 89692862364.08612\n",
      "Epoch: 530 Loss: 89585260353.84297\n",
      "Epoch: 531 Loss: 89589616803.50659\n",
      "Epoch: 532 Loss: 89618372741.04245\n",
      "Epoch: 533 Loss: 89578349269.22543\n",
      "Epoch: 534 Loss: 89615985472.57896\n",
      "Epoch: 535 Loss: 89630698151.47565\n",
      "Epoch: 536 Loss: 89669384133.6517\n",
      "Epoch: 537 Loss: 89803620913.19345\n",
      "Epoch: 538 Loss: 89779946428.2707\n",
      "Epoch: 539 Loss: 89666651085.79254\n",
      "Epoch: 540 Loss: 89539403433.5888\n",
      "Epoch: 541 Loss: 89477712815.71515\n",
      "Epoch: 542 Loss: 89449234761.8444\n",
      "Epoch: 543 Loss: 89489030481.98886\n",
      "Epoch: 544 Loss: 89532802937.06706\n",
      "Epoch: 545 Loss: 89605503882.2089\n",
      "Epoch: 546 Loss: 89698918980.48415\n",
      "Epoch: 547 Loss: 89729791936.98363\n",
      "Epoch: 548 Loss: 89611242919.32677\n",
      "Epoch: 549 Loss: 89474582235.89655\n",
      "Epoch: 550 Loss: 89401999844.98851\n",
      "Epoch: 551 Loss: 89465075280.5237\n",
      "Epoch: 552 Loss: 89394652262.27571\n",
      "Epoch: 553 Loss: 89351571287.73187\n",
      "Epoch: 554 Loss: 89404954655.41388\n",
      "Epoch: 555 Loss: 89342342417.53975\n",
      "Epoch: 556 Loss: 89485541402.1583\n",
      "Epoch: 557 Loss: 89634842896.3507\n",
      "Epoch: 558 Loss: 89625610012.58739\n",
      "Epoch: 559 Loss: 89471134026.6392\n",
      "Epoch: 560 Loss: 89369576625.54588\n",
      "Epoch: 561 Loss: 89270562340.0806\n",
      "Epoch: 562 Loss: 89304202790.07063\n",
      "Epoch: 563 Loss: 89278657202.10768\n",
      "Epoch: 564 Loss: 89281282787.90508\n",
      "Epoch: 565 Loss: 89244855419.1774\n",
      "Epoch: 566 Loss: 89283685807.12775\n",
      "Epoch: 567 Loss: 89397906214.55731\n",
      "Epoch: 568 Loss: 89561639968.74362\n",
      "Epoch: 569 Loss: 89454364498.82259\n",
      "Epoch: 570 Loss: 89256451980.7158\n",
      "Epoch: 571 Loss: 89268373162.89542\n",
      "Epoch: 572 Loss: 89261028555.06354\n",
      "Epoch: 573 Loss: 89100453717.53131\n",
      "Epoch: 574 Loss: 89166755436.89423\n",
      "Epoch: 575 Loss: 89145143807.87946\n",
      "Epoch: 576 Loss: 89192536377.92409\n",
      "Epoch: 577 Loss: 89271674535.7062\n",
      "Epoch: 578 Loss: 89336821017.80904\n",
      "Epoch: 579 Loss: 89484504054.0839\n",
      "Epoch: 580 Loss: 89459791812.29655\n",
      "Epoch: 581 Loss: 89108438347.51425\n",
      "Epoch: 582 Loss: 89120931358.21829\n",
      "Epoch: 583 Loss: 89021569414.68773\n",
      "Epoch: 584 Loss: 89081077205.85597\n",
      "Epoch: 585 Loss: 89065216295.70596\n",
      "Epoch: 586 Loss: 89057051145.30911\n",
      "Epoch: 587 Loss: 89001881925.17116\n",
      "Epoch: 588 Loss: 88975877701.41678\n",
      "Epoch: 589 Loss: 89135895888.86003\n",
      "Epoch: 590 Loss: 89105864352.12096\n",
      "Epoch: 591 Loss: 89320841835.03207\n",
      "Epoch: 592 Loss: 89421472403.03838\n",
      "Epoch: 593 Loss: 89223399289.04086\n",
      "Epoch: 594 Loss: 88956386758.77353\n",
      "Epoch: 595 Loss: 88925505271.10738\n",
      "Epoch: 596 Loss: 88954338827.04398\n",
      "Epoch: 597 Loss: 88869878088.03847\n",
      "Epoch: 598 Loss: 88926263000.4145\n",
      "Epoch: 599 Loss: 88997200171.65218\n",
      "Epoch: 600 Loss: 89149614798.65189\n",
      "Epoch: 601 Loss: 89278364473.875\n",
      "Epoch: 602 Loss: 89080898722.45747\n",
      "Epoch: 603 Loss: 88881699270.99974\n",
      "Epoch: 604 Loss: 88853035148.24814\n",
      "Epoch: 605 Loss: 88871518437.74216\n",
      "Epoch: 606 Loss: 88903447719.9026\n",
      "Epoch: 607 Loss: 88888060479.17973\n",
      "Epoch: 608 Loss: 89042750395.23343\n",
      "Epoch: 609 Loss: 89099046998.03036\n",
      "Epoch: 610 Loss: 89123838746.13652\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[240], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# train pibi-net\u001b[39;00m\n\u001b[1;32m     13\u001b[0m iterations \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1_001\u001b[39m\n\u001b[0;32m---> 14\u001b[0m pibi, loss_values \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_pibi\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpibi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimiser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmse_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m00\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_int\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_now\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_plots\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[239], line 13\u001b[0m, in \u001b[0;36mtrain_pibi\u001b[0;34m(iterations, pibi, optimiser, mse_loss, data, data_n, n_samples, n_int, time_now, show_plots)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# compute data loss\u001b[39;00m\n\u001b[1;32m     12\u001b[0m pibi\u001b[38;5;241m.\u001b[39mresample()\n\u001b[0;32m---> 13\u001b[0m u_int_data \u001b[38;5;241m=\u001b[39m \u001b[43mpibi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_u_inside\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m loss \u001b[38;5;241m=\u001b[39m mse_loss(u_int_data, data[:,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     15\u001b[0m loss_values\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "Cell \u001b[0;32mIn[234], line 78\u001b[0m, in \u001b[0;36mFCNN.predict_u_inside\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpredict_u_inside\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 78\u001b[0m     single_layer, double_layer, source_term \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvmapped_potential_inside\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m     u_int_data \u001b[38;5;241m=\u001b[39m (single_layer\u001b[38;5;241m.\u001b[39msqueeze() \u001b[38;5;241m-\u001b[39m double_layer\u001b[38;5;241m.\u001b[39msqueeze() \u001b[38;5;241m+\u001b[39m source_term\u001b[38;5;241m.\u001b[39msqueeze())\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m u_int_data\n",
      "File \u001b[0;32m~/miniconda3/envs/bem/lib/python3.13/site-packages/torch/_functorch/apis.py:202\u001b[0m, in \u001b[0;36mvmap.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvmap_impl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/bem/lib/python3.13/site-packages/torch/_functorch/vmap.py:334\u001b[0m, in \u001b[0;36mvmap_impl\u001b[0;34m(func, in_dims, out_dims, randomness, chunk_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _chunked_vmap(\n\u001b[1;32m    324\u001b[0m         func,\n\u001b[1;32m    325\u001b[0m         flat_in_dims,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    331\u001b[0m     )\n\u001b[1;32m    333\u001b[0m \u001b[38;5;66;03m# If chunk_size is not specified.\u001b[39;00m\n\u001b[0;32m--> 334\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_flat_vmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_in_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs_spec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/bem/lib/python3.13/site-packages/torch/_functorch/vmap.py:484\u001b[0m, in \u001b[0;36m_flat_vmap\u001b[0;34m(func, batch_size, flat_in_dims, flat_args, args_spec, out_dims, randomness, **kwargs)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m vmap_increment_nesting(batch_size, randomness) \u001b[38;5;28;01mas\u001b[39;00m vmap_level:\n\u001b[1;32m    481\u001b[0m     batched_inputs \u001b[38;5;241m=\u001b[39m _create_batched_inputs(\n\u001b[1;32m    482\u001b[0m         flat_in_dims, flat_args, vmap_level, args_spec\n\u001b[1;32m    483\u001b[0m     )\n\u001b[0;32m--> 484\u001b[0m     batched_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatched_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    485\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unwrap_batched(batched_outputs, out_dims, vmap_level, batch_size, func)\n",
      "Cell \u001b[0;32mIn[234], line 60\u001b[0m, in \u001b[0;36mFCNN.calc_potentials_inside\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     58\u001b[0m G \u001b[38;5;241m=\u001b[39m fundamental_solution(x, y)\n\u001b[1;32m     59\u001b[0m grad_ones \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones_like(h_y)\n\u001b[0;32m---> 60\u001b[0m dh_dy \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_ones\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     61\u001b[0m dh_dn \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(dh_dy \u001b[38;5;241m*\u001b[39m normal_y, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     62\u001b[0m single_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m\u001b[38;5;241m*\u001b[39mside\u001b[38;5;241m*\u001b[39mtorch\u001b[38;5;241m.\u001b[39mmean(G \u001b[38;5;241m*\u001b[39m dh_dn)\n",
      "File \u001b[0;32m~/miniconda3/envs/bem/lib/python3.13/site-packages/torch/autograd/__init__.py:502\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched, materialize_grads)\u001b[0m\n\u001b[1;32m    498\u001b[0m     result \u001b[38;5;241m=\u001b[39m _vmap_internals\u001b[38;5;241m.\u001b[39m_vmap(vjp, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, allow_none_pass_through\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(\n\u001b[1;32m    499\u001b[0m         grad_outputs_\n\u001b[1;32m    500\u001b[0m     )\n\u001b[1;32m    501\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 502\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_outputs_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m materialize_grads:\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m    513\u001b[0m         result[i] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tensor_like(inputs[i])\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(inputs))\n\u001b[1;32m    515\u001b[0m     ):\n",
      "File \u001b[0;32m~/miniconda3/envs/bem/lib/python3.13/site-packages/torch/autograd/graph.py:824\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    823\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 824\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    828\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "show_plots = True\n",
    "\n",
    "# take samples\n",
    "time_now = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "data = torch.tensor(XU_lhs, dtype=torch.float64)\n",
    "data_ = torch.tensor(XU_grid, dtype=torch.float64)\n",
    "\n",
    "# pibi initialisation\n",
    "lr = 0.001 # learning rate\n",
    "pibi, optimiser, mse_loss = initialise_pibi(lr, n_int)\n",
    "    \n",
    "# train pibi-net\n",
    "iterations = 1_001\n",
    "pibi, loss_values = train_pibi(iterations, pibi, optimiser, mse_loss, data, 00, n_samples, n_int, time_now, show_plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd66498e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_ = torch.tensor(XU_grid, dtype=torch.float64)\n",
    "\n",
    "u_pred = pibi.predict_u_inside(data_[:,0:2])\n",
    "u_pibi = u_pred.reshape(X_grid.shape)\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(u_pibi.detach())\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
